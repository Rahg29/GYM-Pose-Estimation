{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "from server.helpers.estimator import TfPoseEstimator\n",
    "from server.helpers.networks import get_graph_path, model_wh\n",
    "from server.helpers.calculate_angle import calculate_angle\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTANTS:\n",
      "BASE_DIR = /Users/cwoozle/Desktop/phormatics/phormatics-master\n",
      "GRAPH_PATH = /Users/cwoozle/Desktop/phormatics/phormatics-master/server/models/mobilenet/graph_opt.pb\n",
      "DATA_PATHS = {'base': '/Users/cwoozle/Desktop/phormatics/phormatics-master/data',\n",
      "              'sample': '/Users/cwoozle/Desktop/phormatics/phormatics-master/data/sample'}\n",
      "PROCESSING_DIMS = (240, 240)\n",
      "CAMERA_NUMBER = 1\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=14)\n",
    "def pdictstr(d):\n",
    "    return \"{\" + pp.pformat(DATA_PATHS)[14:]\n",
    "    \n",
    "print(\"CONSTANTS:\")\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = os.path.abspath('.')\n",
    "GRAPH_PATH = os.path.join(BASE_DIR, 'server', 'models', 'mobilenet', 'graph_opt.pb')\n",
    "DATA_PATHS = {'base': os.path.join(BASE_DIR, 'data'),\n",
    "              'sample': os.path.join(BASE_DIR, 'data', 'sample')}\n",
    "\n",
    "print(\"BASE_DIR =\", BASE_DIR)\n",
    "print(\"GRAPH_PATH =\", GRAPH_PATH)\n",
    "print(\"DATA_PATHS =\", pdictstr(DATA_PATHS))\n",
    "\n",
    "# Processing\n",
    "PROCESSING_DIMS = (240, 240)\n",
    "\n",
    "print(\"PROCESSING_DIMS =\", PROCESSING_DIMS)\n",
    "\n",
    "# Camera\n",
    "CAMERA_NUMBER = 1\n",
    "\n",
    "print(\"CAMERA_NUMBER =\", CAMERA_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/Users/cwoozle/Desktop/phormatics/phormatics-master/server/models/mobilenet/graph_opt.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-934ab52aea9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRAPH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Initialize camera capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/phormatics/phormatics-master/server/helpers/estimator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph_path, target_size)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 80\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /Users/cwoozle/Desktop/phormatics/phormatics-master/server/models/mobilenet/graph_opt.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "def average_or_one(body_parts, idx1, idx2):\n",
    "    if idx1 in body_parts.keys() and idx2 in body_parts.keys():\n",
    "        return ((body_parts[idx1].x + body_parts[idx2].x)/2, (body_parts[idx1].y + body_parts[idx2].y)/2) \n",
    "    elif idx1 in body_parts.keys():\n",
    "        return (body_parts[idx1].x, body_parts[idx1].y)\n",
    "    elif idx2 in body_parts.keys():\n",
    "        return (body_parts[idx2].x, body_parts[idx2].y)\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=(240,240))\n",
    "\n",
    "# Initialize camera capture\n",
    "cam = cv2.VideoCapture(CAMERA_NUMBER)\n",
    "# cam = cv2.VideoCapture('data/sample/curls.mp4')\n",
    "ret_val, image = cam.read()\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    # Read from camera\n",
    "    ret_val, image = cam.read()\n",
    "\n",
    "    # Predict poses\n",
    "    humans = model.inference(image)\n",
    "    \n",
    "    # Get biggest human\n",
    "    human = humans[0]\n",
    "    largest_torso = 0\n",
    "    for h in humans:\n",
    "        try:\n",
    "            # average shoulders\n",
    "            shoulder = average_or_one(h.body_parts, 2, 5)\n",
    "            # average hips\n",
    "            hip = average_or_one(h.body_parts, 8, 11)\n",
    "            \n",
    "            print(shoulder)\n",
    "            print(hip)\n",
    "            \n",
    "            if shoulder and hip:\n",
    "                torso = (hip[0] - shoulder[0])**2 + (hip[1] - shoulder[1])**2\n",
    "                torso = math.sqrt(torso)\n",
    "                \n",
    "                if torso > largest_torso:\n",
    "                    human = h\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    # Draw pose\n",
    "    draw = TfPoseEstimator.draw_humans(image, [human], imgcopy=False)\n",
    "\n",
    "    # Draw fps\n",
    "    fps = 1.0 / (time.time() - fps_time)\n",
    "    cv2.putText(draw,\n",
    "                \"FPS: {}\".format(fps),\n",
    "                (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 0), 2)\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result', draw)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body part mapping\n",
    "Nose = 0\n",
    "\n",
    "Neck = 1\n",
    "\n",
    "RShoulder = 2\n",
    "\n",
    "RElbow = 3\n",
    "\n",
    "RWrist = 4\n",
    "\n",
    "LShoulder = 5\n",
    "\n",
    "LElbow = 6\n",
    "\n",
    "LWrist = 7\n",
    "\n",
    "RHip = 8\n",
    "\n",
    "RKnee = 9\n",
    "\n",
    "RAnkle = 10\n",
    "\n",
    "LHip = 11\n",
    "\n",
    "LKnee = 12\n",
    "\n",
    "LAnkle = 13\n",
    "\n",
    "REye = 14\n",
    "\n",
    "LEye = 15\n",
    "\n",
    "REar = 16\n",
    "\n",
    "LEar = 17\n",
    "\n",
    "Background = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_or_one(body_parts, idx1, idx2):\n",
    "    if idx1 in body_parts.keys() and idx2 in body_parts.keys():\n",
    "        return ((body_parts[idx1].x + body_parts[idx2].x)/2, (body_parts[idx1].y + body_parts[idx2].y)/2) \n",
    "    elif idx1 in body_parts.keys():\n",
    "        return (body_parts[idx1].x, body_parts[idx1].y)\n",
    "    elif idx2 in body_parts.keys():\n",
    "        return (body_parts[idx2].x, body_parts[idx2].y)\n",
    "    else: \n",
    "        return False\n",
    "    \n",
    "def angle_one(body_parts, idx):\n",
    "    return (body_parts[idx].x, body_parts[idx].y)\n",
    "    \n",
    "def analyze_workout(body_parts, side, workout_func):\n",
    "    if side:\n",
    "        return workout_func(body_parts, side)\n",
    "    else:\n",
    "        return workout_func(body_parts)\n",
    "\n",
    "def plank(body_parts):\n",
    "    \"\"\"\n",
    "    Problems:\n",
    "    ->  Deviation in waist:\n",
    "        Body Parts:\n",
    "           L/R Shoulder\n",
    "           L/R Hip\n",
    "           L/R Ankle\n",
    "        Percent Deviation:\n",
    "           (OptimalAngle - AngleDetected)/OptimalAngle * 100\n",
    "        Params:\n",
    "            OptimalAngle = pi\n",
    "            Threshold = 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    def deviation_in_waist(body_parts, optimal_angle, thresh):\n",
    "        # average shoulders\n",
    "        shoulder = average_or_one(body_parts, 2, 5)\n",
    "        # average hips\n",
    "        hip = average_or_one(body_parts, 8, 11)    \n",
    "        # average ankles\n",
    "        ankle = average_or_one(body_parts, 10, 13)\n",
    "        try:\n",
    "            # calculate angle\n",
    "            angle_detected = calculate_angle(shoulder, hip, ankle)\n",
    "        except TypeError as e:\n",
    "            raise e\n",
    "        # calculate percent deviation\n",
    "        deviation = (optimal_angle - angle_detected)/optimal_angle * 100\n",
    "        return deviation\n",
    "    \n",
    "    \n",
    "    return deviation_in_waist(body_parts, math.pi, 0.1)\n",
    "\n",
    "def curl(body_parts, side):\n",
    "    \"\"\"\n",
    "    side - left or right, depending on user\n",
    "    \n",
    "    Problems:\n",
    "    ->  Horizontal deviation in humerous to upper body:\n",
    "        Body parts:\n",
    "            L//R Shoulder\n",
    "            L//R Elbow\n",
    "            L//R Hip\n",
    "        Percent Deviation:\n",
    "            (OptimalAngle - AngleDetected)/OptimalAngle * 100\n",
    "        Params:\n",
    "            OptimalAngle = 0\n",
    "            Threshold = 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    def horizontal_deviation_of_elbow(body_parts, side, optimal_angle, thresh):\n",
    "        try:\n",
    "            if side == 'L':\n",
    "                shoulder = angle_one(body_parts, 5)\n",
    "                elbow = angle_one(body_parts, 6)\n",
    "                hip = angle_one(body_parts, 11)\n",
    "            elif side == 'R':\n",
    "                shoulder = angle_one(body_parts, 2)\n",
    "                elbow = angle_one(body_parts, 3)\n",
    "                hip = angle_one(body_parts, 8)\n",
    "            else:\n",
    "                return -1\n",
    "        except KeyError as e:\n",
    "            return -1\n",
    "        \n",
    "        try:\n",
    "            if shoulder and hip and ankle:\n",
    "                # calculate angle\n",
    "                angle_detected = calculate_angle(shoulder, hip, ankle)\n",
    "            else:\n",
    "                return -1\n",
    "        except TypeError as e:\n",
    "            raise e\n",
    "        \n",
    "        # calculate percent deviation\n",
    "        deviation = (optimal_angle - angle_detected)/optimal_angle * 100\n",
    "        return deviation\n",
    "        \n",
    "        \n",
    "        \n",
    "    return horizontal_deviation_of_elbow(body_parts, side, 0, 0.1)\n",
    "\n",
    "def pushup(body_parts):\n",
    "    \"\"\"\n",
    "    Problems:\n",
    "    ->  Deviation in waist:\n",
    "        Body Parts:\n",
    "           L/R Shoulder\n",
    "           L/R Hip\n",
    "           L/R Ankle\n",
    "        Percent Deviation:\n",
    "           (OptimalAngle - AngleDetected)/OptimalAngle * 100\n",
    "        Params:\n",
    "            OptimalAngle = pi\n",
    "            Threshold = 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    def deviation_in_waist(body_parts, optimal_angle, thresh):\n",
    "        # average shoulders\n",
    "        shoulder = average_or_one(body_parts, 2, 5)\n",
    "        # average hips\n",
    "        hip = average_or_one(body_parts, 8, 11)    \n",
    "        # average ankles\n",
    "        ankle = average_or_one(body_parts, 10, 13)\n",
    "        try:\n",
    "            if shoulder and hip and ankle:\n",
    "                # calculate angle\n",
    "                angle_detected = calculate_angle(shoulder, hip, ankle)\n",
    "            else:\n",
    "                return -1\n",
    "        except TypeError as e:\n",
    "            raise e\n",
    "        # calculate percent deviation\n",
    "        deviation = (optimal_angle - angle_detected)/optimal_angle * 100\n",
    "        return deviation\n",
    "\n",
    "\n",
    "    return deviation_in_waist(body_parts, math.pi, 0.1)\n",
    "\n",
    "def squat(body_parts):\n",
    "    \"\"\"\n",
    "    Problems:\n",
    "    - Squat depth\n",
    "        Body Parts:\n",
    "           L/R Ankle\n",
    "           L/R Knee\n",
    "           L/R Hip\n",
    "        Percent Deviation:\n",
    "           (OptimalAngle - AngleDetected)/OptimalAngle * 100\n",
    "        Params:\n",
    "            OptimalAngle = pi/2\n",
    "            Threshold = TBD\n",
    "    - Forward knee movement\n",
    "        Body Parts:\n",
    "            L/R Ankle\n",
    "            L/R Knee\n",
    "        Percent Deviation:\n",
    "           (X_ANKLE - X_KNEE)/TibiaLength * 100\n",
    "        Params:\n",
    "            OptimalDeviation = 0\n",
    "            Threshold = TBD\n",
    "    - 'Divebombing'\n",
    "        Body Parts:\n",
    "            L/R Shoulder\n",
    "            L/R Hip\n",
    "        Percent Deviation:\n",
    "           (X_SHOULDER - X_HIP)/TorsoLength * 100\n",
    "        Params:\n",
    "            OptimalDeviation = 0\n",
    "            Threshold = TBD\n",
    "    \"\"\"\n",
    "    def squat_depth_angle(body_parts, optimal_angle, thresh):\n",
    "        ankle = average_or_one(body_parts, 10, 13)\n",
    "        knee = average_or_one(body_parts, 9, 12)\n",
    "        hip = average_or_one(body_parts, 8, 11)\n",
    "        try:\n",
    "            if ankle and knee and hip:\n",
    "                angle_detected = calculate_angle(ankle, knee, hip)\n",
    "            else:\n",
    "                 return -1\n",
    "        except TypeError as e:\n",
    "            raise e\n",
    "        # calculate percent deviation\n",
    "        deviation = (optimal_angle - angle_detected)/optimal_angle * 100\n",
    "        return deviation\n",
    "    return squat_depth_angle(body_parts, (math.pi)/2, 0.1)\n",
    "\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_workout() missing 1 required positional argument: 'workout_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-34fb03a0ee22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Analyze workout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdev1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_workout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhumans1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_workout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdev2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_workout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhumans2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_workout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: analyze_workout() missing 1 required positional argument: 'workout_func'"
     ]
    }
   ],
   "source": [
    "# HARDCODE\n",
    "current_workout = plank\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=PROCESSING_DIMS)\n",
    "\n",
    "# Initialize camera capture\n",
    "image1 = cv2.imread(os.path.join(DATA_PATHS['sample'], 'plank', 'plank-up.jpg'))\n",
    "image2 = cv2.imread(os.path.join(DATA_PATHS['sample'], 'plank', 'plank-down.jpg'))\n",
    "\n",
    "# Predict poses\n",
    "humans1 = model.inference(image1)\n",
    "humans2 = model.inference(image2)\n",
    "\n",
    "# Analyze workout\n",
    "dev1 = analyze_workout(humans1[0].body_parts, current_workout)\n",
    "dev2 = analyze_workout(humans2[0].body_parts, current_workout)\n",
    "\n",
    "# Draw pose\n",
    "draw1 = TfPoseEstimator.draw_humans(image1, humans1, imgcopy=False)\n",
    "draw2 = TfPoseEstimator.draw_humans(image2, humans2, imgcopy=False)\n",
    "\n",
    "# Draw angle\n",
    "cv2.putText(draw1,\n",
    "                \"Deviation: {}\".format(dev1),\n",
    "                (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "cv2.putText(draw2,\n",
    "                \"Deviation: {}\".format(dev2),\n",
    "                (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result1', draw1)\n",
    "    cv2.imshow('tf-pose-estimation result2', draw2)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODE\n",
    "current_workout = curl\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=PROCESSING_DIMS)\n",
    "\n",
    "# Initialize camera capture\n",
    "image1 = cv2.imread(os.path.join(DATA_PATHS['sample'], 'curls', 'curl-up.png'))\n",
    "image2 = cv2.imread(os.path.join(DATA_PATHS['sample'], 'curls', 'curl-down.png'))\n",
    "\n",
    "# Predict poses\n",
    "humans1 = model.inference(image1)\n",
    "humans2 = model.inference(image2)\n",
    "\n",
    "# Analyze workout\n",
    "dev1 = analyze_workout(humans1[0].body_parts, 'L', current_workout)\n",
    "dev2 = analyze_workout(humans2[0].body_parts, 'L', current_workout)\n",
    "\n",
    "# Draw pose\n",
    "draw1 = TfPoseEstimator.draw_humans(image1, humans1, imgcopy=False)\n",
    "draw2 = TfPoseEstimator.draw_humans(image2, humans2, imgcopy=False)\n",
    "\n",
    "# Draw angle\n",
    "cv2.putText(draw1,\n",
    "                \"Deviation: {}\".format(dev1),\n",
    "                (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "cv2.putText(draw2,\n",
    "                \"Deviation: {}\".format(dev2),\n",
    "                (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result1', draw1)\n",
    "    cv2.imshow('tf-pose-estimation result2', draw2)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_human(humans):\n",
    "    # Get biggest human\n",
    "    human = None\n",
    "    largest_torso = 0\n",
    "    for h in humans:\n",
    "        try:\n",
    "            # average shoulders\n",
    "            shoulder = average_or_one(h.body_parts, 2, 5)\n",
    "            # average hips\n",
    "            hip = average_or_one(h.body_parts, 8, 11)\n",
    "            \n",
    "            if shoulder and hip:\n",
    "                torso = (hip[0] - shoulder[0])**2 + (hip[1] - shoulder[1])**2\n",
    "                torso = math.sqrt(torso)\n",
    "                \n",
    "                if torso > largest_torso:\n",
    "                    largest_torso = torso\n",
    "                    human = h\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    return human\n",
    "\n",
    "def draw_sizes(image, humans):\n",
    "    imw, imh = image.shape[0], image.shape[1]\n",
    "    human = None\n",
    "    largest_torso = 0\n",
    "    for h in humans:\n",
    "        try:\n",
    "            # average shoulders\n",
    "            shoulder = average_or_one(h.body_parts, 2, 5)\n",
    "            # average hips\n",
    "            hip = average_or_one(h.body_parts, 8, 11)\n",
    "            \n",
    "            if shoulder and hip:\n",
    "                torso = (hip[0] - shoulder[0])**2 + (hip[1] - shoulder[1])**2\n",
    "                torso = math.sqrt(torso)\n",
    "                \n",
    "                if torso > largest_torso:\n",
    "                    largest_torso = torso\n",
    "                    human = h\n",
    "                    cv2.putText(image,\n",
    "                                \"SIZE: {}\".format(torso),\n",
    "                                (int(shoulder[0]*imw-5), int(shoulder[1]*imh)),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(image,\n",
    "                                \"SIZE: {}\".format(torso),\n",
    "                                (int(shoulder[0*imw]-5), int(shoulder[1]*imh)),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (0, 255, 0), 2)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    return image\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODE\n",
    "current_workout = plank\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=PROCESSING_DIMS)\n",
    "\n",
    "# Initialize camera capture\n",
    "cam = cv2.VideoCapture(CAMERA_NUMBER)\n",
    "ret_val, image = cam.read()\n",
    "\n",
    "rows, cols = image.shape[0], image.shape[1]\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    # Read from camera\n",
    "    ret_val, image = cam.read()\n",
    "\n",
    "    image = imutils.rotate(image, 90)\n",
    "\n",
    "    # Predict poses\n",
    "    humans = model.inference(image)\n",
    "    \n",
    "    subject = get_best_human(humans)\n",
    "\n",
    "    try:\n",
    "        # Analyze workout\n",
    "        dev = analyze_workout(subject.body_parts, current_workout)\n",
    "    except IndexError as e:\n",
    "        image = imutils.rotate(image, -90)\n",
    "        cv2.imshow('tf-pose-estimation result', image)\n",
    "        fps_time = time.time()\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        continue\n",
    "        \n",
    "\n",
    "    # Draw pose\n",
    "    draw = TfPoseEstimator.draw_humans(image, [subject], imgcopy=False)\n",
    "    draw = imutils.rotate(draw, -90)\n",
    "\n",
    "    # Draw angle\n",
    "    cv2.putText(draw,\n",
    "                    \"Deviation: {}\".format(dev),\n",
    "                    (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0), 2)\n",
    "\n",
    "    # Draw fps\n",
    "    fps = 1.0 / (time.time() - fps_time)\n",
    "    cv2.putText(draw,\n",
    "                \"FPS: {}\".format(fps),\n",
    "                (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 0), 2)\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result', draw)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODE\n",
    "current_workout = curl\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=PROCESSING_DIMS)\n",
    "\n",
    "# Initialize camera capture\n",
    "cam = cv2.VideoCapture(CAMERA_NUMBER)\n",
    "ret_val, image = cam.read()\n",
    "\n",
    "rows, cols = image.shape[0], image.shape[1]\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    # Read from camera\n",
    "    ret_val, image = cam.read()\n",
    "\n",
    "    # Predict poses\n",
    "    humans = model.inference(image)\n",
    "\n",
    "    try:\n",
    "        subject = get_best_human(humans)\n",
    "        image = draw_sizes(image, humans)\n",
    "        if subject == None:\n",
    "            raise IndexError()\n",
    "        # Analyze workout\n",
    "        dev = analyze_workout(subject.body_parts, 'L', current_workout)\n",
    "    except IndexError as e:\n",
    "        cv2.imshow('tf-pose-estimation result', image)\n",
    "        fps_time = time.time()\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        continue\n",
    "        \n",
    "\n",
    "    # Draw pose\n",
    "    draw = TfPoseEstimator.draw_humans(image, [subject], imgcopy=False)\n",
    "\n",
    "    # Draw angle\n",
    "    cv2.putText(draw,\n",
    "                    \"Deviation: {}\".format(dev),\n",
    "                    (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0), 2)\n",
    "\n",
    "    # Draw fps\n",
    "    fps = 1.0 / (time.time() - fps_time)\n",
    "    cv2.putText(draw,\n",
    "                \"FPS: {}\".format(fps),\n",
    "                (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 0), 2)\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result', draw)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "#     time.sleep(1)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/home/jasonchin/projects/phorm/phormatics/models/mobilenet/graph_opt.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6084296fb0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRAPH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROCESSING_DIMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize camera capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/phorm/phormatics/helpers/estimator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph_path, target_size)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phorm/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phorm/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 80\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phorm/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/jasonchin/projects/phorm/phormatics/models/mobilenet/graph_opt.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "# HARDCODE\n",
    "current_workout = pushup\n",
    "\n",
    "# Initialize fps counter\n",
    "fps_time = 0\n",
    "\n",
    "# Load model\n",
    "model = TfPoseEstimator(GRAPH_PATH, target_size=PROCESSING_DIMS)\n",
    "\n",
    "# Initialize camera capture\n",
    "cam = cv2.VideoCapture(CAMERA_NUMBER)\n",
    "ret_val, image = cam.read()\n",
    "\n",
    "rows, cols = image.shape[0], image.shape[1]\n",
    "\n",
    "# Read loop\n",
    "while True:\n",
    "    # Read from camera\n",
    "    ret_val, image = cam.read()\n",
    "    \n",
    "    image = imutils.rotate(image, 90)\n",
    "\n",
    "    # Predict poses\n",
    "    humans = model.inference(image)\n",
    "\n",
    "    try:\n",
    "        subject = get_best_human(humans)\n",
    "        image = draw_sizes(image, humans)\n",
    "        if subject == None:\n",
    "            raise IndexError()\n",
    "        # Analyze workout\n",
    "        dev = analyze_workout(subject.body_parts, None, current_workout)\n",
    "    except IndexError as e:\n",
    "        image = imutils.rotate(image, -90)\n",
    "        cv2.imshow('tf-pose-estimation result', image)\n",
    "        fps_time = time.time()\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        continue\n",
    "        \n",
    "\n",
    "    # Draw pose\n",
    "    draw = TfPoseEstimator.draw_humans(image, [subject], imgcopy=False)\n",
    "    \n",
    "    image = imutils.rotate(draw, -90)\n",
    "\n",
    "    # Draw angle\n",
    "    cv2.putText(draw,\n",
    "                    \"Deviation: {}\".format(dev),\n",
    "                    (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0), 2)\n",
    "\n",
    "    # Draw fps\n",
    "    fps = 1.0 / (time.time() - fps_time)\n",
    "    cv2.putText(draw,\n",
    "                \"FPS: {}\".format(fps),\n",
    "                (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 0), 2)\n",
    "    \n",
    "    # Show image\n",
    "    cv2.imshow('tf-pose-estimation result', draw)\n",
    "\n",
    "    # Restart FPS counter\n",
    "    fps_time = time.time()\n",
    "#     time.sleep(1)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
